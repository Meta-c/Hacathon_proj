{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import splitfolders\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXING IMAGES EXTENSIONS\n",
    "\n",
    "for name in glob.glob('/Hacathon_proj/dataset/images/*'):\n",
    "    if '.JPG' in name:\n",
    "        os.rename(name,name.replace('JPG','jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_csv(\"/Hacathon_proj/dataset/train.csv\")\n",
    "test_dataset=pd.read_csv(\"/Hacathon_proj/dataset/test.csv\")\n",
    "images_directory='/Hacathon_proj/dataset/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions=train_dataset.iloc[:,3:]\n",
    "dimensions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dictionary={\n",
    "    3:'GARBAGE',\n",
    "    7:'BAD_BILLBOARD',\n",
    "    8:'SAND_ON_ROAD',\n",
    "    0:'GRAFFITI',\n",
    "    2:'POTHOLES',\n",
    "    9:'CLUTTER_SIDEWALK',\n",
    "    4:'CONSTRUCTION_ROAD',\n",
    "    5:'BROKEN_SIGNAGE',\n",
    "    10:'UNKEPT_FACADE',\n",
    "    1:'FADED_SIGNAGE',\n",
    "    6:'BAD_STREETLIGHT'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory=images_directory\n",
    "img_path=[]\n",
    "count=0\n",
    "for image in train_dataset['image_path']:\n",
    "    try:\n",
    "        img_path.append(train_directory+train_dataset['image_path'][count])\n",
    "        count+=1\n",
    "    except:\n",
    "        print('dfvd')\n",
    "        count+=1\n",
    "        continue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "images_width=[]\n",
    "images_height=[]\n",
    "train_y=[]\n",
    "count=0\n",
    "for img in range(0,10000):\n",
    "    try:\n",
    "        img=cv2.imread(img_path[count])\n",
    "        img=cv2.resize(img,(960,540))\n",
    "        xmin=int(train_dataset['xmin'][count])\n",
    "        ymin=int(train_dataset['ymin'][count])\n",
    "        xmax=int(train_dataset['xmax'][count])\n",
    "        ymax=int(train_dataset['ymax'][count])\n",
    "        img=img[ymin:ymax, xmin:xmax]\n",
    "        height,width,rgb=img.shape\n",
    "        if width >=128 and height >=64:\n",
    "            train_y.append(train_dataset['class'][count])\n",
    "            images_width.append(width)\n",
    "            images_height.append(height)\n",
    "            img=cv2.resize(img,(128,64))\n",
    "            train_x.append(img)\n",
    "        count+=1\n",
    "    except:\n",
    "        count+=1\n",
    "        continue\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=[]\n",
    "test_y=[]\n",
    "count=10001\n",
    "for img in range(10001,15000):\n",
    "    try:\n",
    "        img=cv2.imread(img_path[count])\n",
    "        img=cv2.resize(img,(960,540))\n",
    "        xmin=int(train_dataset['xmin'][count])\n",
    "        ymin=int(train_dataset['ymin'][count])\n",
    "        xmax=int(train_dataset['xmax'][count])\n",
    "        ymax=int(train_dataset['ymax'][count])\n",
    "        img=img[ymin:ymax, xmin:xmax]\n",
    "        height,width,rgb=img.shape\n",
    "        if width >=128 and height >=64:\n",
    "            test_y.append(train_dataset['class'][count])\n",
    "            img=cv2.resize(img,(128,64))\n",
    "            test_x.append(img)\n",
    "        count+=1\n",
    "    except:\n",
    "        count+=1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Generator For Augmentation \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,shear_range=15,width_shift_range=0.05,\n",
    "          height_shift_range=0.05,zoom_range=0.1\n",
    "   \n",
    "    \n",
    "    )\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_x=np.array(train_x).reshape(-1,128,64,3)\n",
    "# for img in train_x:\n",
    "#     img=np.array(img).reshape(-1,128,64,3)\n",
    "#     train_array.append(img)\n",
    "\n",
    "train_y = np.array([np.array(val) for val in train_y])\n",
    "\n",
    "#Normalization \n",
    "# train_array=np.array(train_array)\n",
    "train_x=train_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=np.array(test_x).reshape(-1,128,64,3)\n",
    "test_y = np.array([np.array(val) for val in test_y])\n",
    "test_x=test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(train_y[65])\n",
    "plt.imshow(train_x[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=train_datagen.flow(train_x,train_y,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "def myModel():\n",
    "    input = keras.Input(shape= (128,64,3))\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu',)(input)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu',)(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu',)(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu',)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    out1 = keras.layers.Dense(11, activation='softmax')(x)\n",
    "    model = keras.models.Model(inputs=input,outputs=[out1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =myModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "[print(o.shape, o.dtype) for o in model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y, batch_size = 64, epochs = 50,verbose=1,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image=cv2.imread(images_directory+train_dataset['image_path'][2400])\n",
    "# image=cv2.resize(image,(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_x,test_y, verbose=1,batch_size=64)\n",
    "print(\"The accuracy of the model is:\")\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path[6070]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(img_path[17560])\n",
    "    \n",
    "temp = cv2.resize(image,(960,540))\n",
    "xmin=int(train_dataset['xmin'][17460])\n",
    "ymin=int(train_dataset['ymin'][17460])\n",
    "xmax=int(train_dataset['xmax'][17460])\n",
    "ymax=int(train_dataset['ymax'][17460])\n",
    "temp=temp[ymin:ymax, xmin:xmax]\n",
    "plt.title(train_dataset['name'][17460])\n",
    "plt.imshow(temp)\n",
    "temp=cv2.resize(temp,(128,64))\n",
    "temp = tf.convert_to_tensor(temp)\n",
    "temp = tf.reshape(temp,(-1,128,64,3))\n",
    "temp = temp/255\n",
    "pred= model.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(img_path[17460])\n",
    "plt.title(train_dataset['name'][17460])\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dictionary[np.argmax(pred)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "253ae6feff4fd1b8c72e2ad785b88438628b5b076110376ae0f22865de7b119a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
